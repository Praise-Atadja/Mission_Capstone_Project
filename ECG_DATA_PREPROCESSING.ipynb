{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praise-Atadja/Mission_Capstone_Project/blob/main/ECG_DATA_PREPROCESSING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzr3UnZEo8q_"
      },
      "source": [
        "\n",
        "\n",
        "# **PROJECT NAME:**\n",
        "\n",
        "##CARDIAC TEK (Improving Cardiovascular Care In Africa Through AI-Driven Diagnosis And Treatment Solutions)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "(***This project is to digitize, interpret, offer diagnosis and recommendations on ECG report for Myocardiac Infarction ***)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raZ4c6dbpA3d"
      },
      "source": [
        "\n",
        "\n",
        "# **CASE STUDY IMPLEMENTATION**\n",
        "\n",
        "**Abstract**:\n",
        "Cardiovascular disease (CVD) is the leading cause of death worldwide, with a significant burden in Africa due to limited healthcare access and infrastructure. This research investigates the potential of Artificial Intelligence (AI) to improve CVD care in Africa by enhancing diagnostics, treatment planning, and patient management. It focuses on developing scalable AI solutions tailored to African healthcare systems, assessing their impact, and identifying barriers to adoption, such as infrastructure challenges and data privacy concerns. The study aims to advance global health equity by integrating AI into routine clinical practice.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWMcfxh3pJ2V"
      },
      "source": [
        "# **Data Processing Approach for Portfolio Project**\n",
        "\n",
        "---\n",
        "\n",
        "   \n",
        "***Data Sources***:\n",
        "\n",
        "The ECG images dataset from **Ch. Pervaiz Elahi Institute of Cardiology Multan, Pakistan** is designed to aid researchers in advancing cardiovascular disease research. This dataset is structured with electrocardiogram (ECG) images of various categories of cardiac patients and healthy individuals, providing comprehensive data for scientific analysis.\n",
        "\n",
        "### Key Information:\n",
        "\n",
        "- **Total Size**: 194 MB\n",
        "- **Purpose**: To assist in research focused on cardiovascular diseases, specifically by providing ECG data of patients with different cardiac conditions.\n",
        "\n",
        "### File Organization:\n",
        "Each category includes ECG images arranged by 12 leads, providing a standard and comprehensive view of the heart's electrical activity. This dataset is valuable for developing machine learning models to identify, classify, and predict cardiovascular conditions based on ECG patterns.\n",
        "\n",
        "### Use Case:\n",
        "The dataset serves as a resource for developing algorithms that can differentiate between normal and abnormal heart activity, detect myocardial infarction, and study the effects of a history of MI on ECG readings. It is intended to benefit the scientific community in exploring cardiovascular health using image-based data.\n",
        "\n",
        "Link to data source : https://data.mendeley.com/datasets/gwbz3fsgp8/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5YHkTutpPSv"
      },
      "source": [
        "### **Short Description of the Data:**\n",
        "\n",
        "### Dataset Breakdown:\n",
        "1. **ECG Images of Myocardial Infarction (MI) Patients**:\n",
        "   - **Quantity**: 240 patients, each with 12-lead ECG images.\n",
        "   - **Total Images**: 2,880 images.\n",
        "   - **Condition**: These images capture the heart activity of patients who have suffered a myocardial infarction (heart attack).\n",
        "   \n",
        "2. **ECG Images of Patients with Abnormal Heartbeat**:\n",
        "   - **Quantity**: 233 patients, each with 12-lead ECG images.\n",
        "   - **Total Images**: 2,796 images.\n",
        "   - **Condition**: These are ECGs from patients exhibiting arrhythmias or other abnormal heart rhythms.\n",
        "\n",
        "3. **ECG Images of Patients with a History of Myocardial Infarction (MI)**:\n",
        "   - **Quantity**: 172 patients, each with 12-lead ECG images.\n",
        "   - **Total Images**: 2,064 images.\n",
        "   - **Condition**: These ECGs are from patients with a documented history of MI, but they may not currently be experiencing an active heart attack.\n",
        "\n",
        "4. **Normal Person ECG Images**:\n",
        "   - **Quantity**: 284 healthy individuals, each with 12-lead ECG images.\n",
        "   - **Total Images**: 3,408 images.\n",
        "   - **Condition**: These ECGs represent normal heart activity with no signs of cardiovascular disease.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xmZ_507lw6Qh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7da839f-fbc2-40e0-bfee-ec5ee1e2e76c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Import Necessary Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "import cv2\n",
        "import os\n",
        "from scipy import signal\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA PREPROCESSING/FEATURE EXTRACTION**"
      ],
      "metadata": {
        "id": "Sq6m30cb0vcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading datasets"
      ],
      "metadata": {
        "id": "eW8GJncjzQqB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s9581c8FdHeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8211dd32-55e4-44c5-d2a1-e29e50b43ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the dataset folder: ['ECG Images of Myocardial Infarction Patients (240x12=2880)', 'ECG Images of Patient that have History of MI (172x12=2064)', 'ECG Images of Patient that have abnormal heartbeat (233x12=2796)', 'Normal Person ECG Images (284x12=3408)']\n"
          ]
        }
      ],
      "source": [
        "#load data\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/MISSION CAPSTONE/ECG_DATASET\"\n",
        "files = os.listdir(dataset_path)\n",
        "print(f\"Files in the dataset folder: {files}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load images"
      ],
      "metadata": {
        "id": "cc8_XyYh3caq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from skimage.io import imread\n",
        "from skimage import img_as_ubyte\n",
        "import numpy as np\n",
        "\n",
        "def load_image(image_path):\n",
        "    \"\"\"\n",
        "    Load an image from the specified path and return it.\n",
        "    If the image is not found or cannot be loaded, returns None.\n",
        "\n",
        "    Parameters:\n",
        "    image_path (str): The path to the image file.\n",
        "\n",
        "    Returns:\n",
        "    ndarray or None: The image array if loaded successfully, None otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        image = imread(image_path)\n",
        "        # Ensure the image is converted to a usable format (e.g., converting to byte format)\n",
        "        image = img_as_ubyte(image)\n",
        "        return image\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at path: {image_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image at path {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def load_images_from_folder(folder_path, valid_extensions=('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')):\n",
        "    \"\"\"\n",
        "    Load all images from the specified folder, filtering by valid extensions.\n",
        "\n",
        "    Parameters:\n",
        "    folder_path (str): The path to the folder containing images.\n",
        "    valid_extensions (tuple): A tuple of valid image file extensions.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of loaded images (ndarrays), with None for failed images.\n",
        "    \"\"\"\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(valid_extensions)]\n",
        "    loaded_images = [load_image(os.path.join(folder_path, img)) for img in image_files]\n",
        "    return loaded_images\n",
        "\n",
        "# Define paths to each folder containing the images\n",
        "MI = '/content/drive/MyDrive/MISSION CAPSTONE/ECG_DATASET/ECG Images of Myocardial Infarction Patients (240x12=2880)'\n",
        "Normal = '/content/drive/MyDrive/MISSION CAPSTONE/ECG_DATASET/Normal Person ECG Images (284x12=3408)'\n",
        "Abnormal ='/content/drive/MyDrive/MISSION CAPSTONE/ECG_DATASET/ECG Images of Patient that have abnormal heartbeat (233x12=2796)'\n",
        "H_MI = '/content/drive/MyDrive/MISSION CAPSTONE/ECG_DATASET/ECG Images of Patient that have History of MI (172x12=2064)'\n",
        "\n",
        "\n",
        "# Load images from each folder\n",
        "MI_images_loaded = load_images_from_folder(MI)\n",
        "Normal_images_loaded = load_images_from_folder(Normal)\n",
        "Abnormal_images_loaded = load_images_from_folder(Abnormal)\n",
        "H_MI_images_loaded = load_images_from_folder(H_MI)\n",
        "\n",
        "# Filter out any None values (images that failed to load)\n",
        "MI_images_loaded = [img for img in MI_images_loaded if img is not None]\n",
        "Normal_images_loaded = [img for img in Normal_images_loaded if img is not None]\n",
        "Abnormal_images_loaded = [img for img in Abnormal_images_loaded if img is not None]\n",
        "H_MI_images_loaded = [img for img in H_MI_images_loaded if img is not None]\n",
        "\n",
        "# Print the number of successfully loaded images for each category\n",
        "print(f\"Successfully loaded {len(MI_images_loaded)} MI images.\")\n",
        "print(f\"Successfully loaded {len(Normal_images_loaded)} Normal images.\")\n",
        "print(f\"Successfully loaded {len(Abnormal_images_loaded)} Abnormal images.\")\n",
        "print(f\"Successfully loaded {len(H_MI_images_loaded)} H_MI images.\")\n"
      ],
      "metadata": {
        "id": "PoIbtlKd3fBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividing ECG image to leads for processing and Looping through the list of ECG lead images to apply preprocessing steps\n"
      ],
      "metadata": {
        "id": "_M0ceoTiSXCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread\n",
        "\n",
        "def convert_image_lead(image_file, parent_folder, output_folder):\n",
        "    \"\"\"\n",
        "    This function extracts the 13 ECG leads from the given image and saves them as separate images.\n",
        "\n",
        "    Parameters:\n",
        "    - image_file: The name of the image file to process.\n",
        "    - parent_folder: The directory where the image is located.\n",
        "    - output_folder: The directory where the lead images will be saved.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read the image from the given folder\n",
        "        image_path = os.path.join(parent_folder, image_file)\n",
        "        image = imread(image_path, plugin='matplotlib')\n",
        "\n",
        "        # Divide the ECG image into 13 leads based on pixel regions\n",
        "        Lead_1 = image[300:600, 150:643]\n",
        "        Lead_2 = image[300:600, 646:1135]\n",
        "        Lead_3 = image[300:600, 1140:1626]\n",
        "        Lead_4 = image[300:600, 1630:2125]\n",
        "        Lead_5 = image[600:900, 150:643]\n",
        "        Lead_6 = image[600:900, 646:1135]\n",
        "        Lead_7 = image[600:900, 1140:1626]\n",
        "        Lead_8 = image[600:900, 1630:2125]\n",
        "        Lead_9 = image[900:1200, 150:643]\n",
        "        Lead_10 = image[900:1200, 646:1135]\n",
        "        Lead_11 = image[900:1200, 1140:1626]\n",
        "        Lead_12 = image[900:1200, 1630:2125]\n",
        "        Lead_13 = image[1250:1480, 150:2125]\n",
        "\n",
        "        # List to store the leads\n",
        "        leads = [Lead_1, Lead_2, Lead_3, Lead_4, Lead_5, Lead_6, Lead_7, Lead_8, Lead_9, Lead_10, Lead_11, Lead_12, Lead_13]\n",
        "\n",
        "        # Create a subfolder for the extracted leads inside the output folder\n",
        "        folder_name = re.sub('.jpg', '', image_file)  # Removing file extension for folder name\n",
        "        lead_output_dir = os.path.join(output_folder, folder_name)\n",
        "        os.makedirs(lead_output_dir, exist_ok=True)\n",
        "\n",
        "        # Loop through the leads and save them as individual images\n",
        "        for idx, lead in enumerate(leads):\n",
        "            fig, ax = plt.subplots()\n",
        "            ax.imshow(lead)\n",
        "            ax.axis('off')\n",
        "            ax.set_title(f\"Lead {idx + 1}\")\n",
        "\n",
        "            # Save the lead image\n",
        "            lead_image_path = os.path.join(lead_output_dir, f\"Lead_{idx + 1}_Signal.png\")\n",
        "            plt.ioff()\n",
        "            fig.savefig(lead_image_path, bbox_inches='tight', pad_inches=0)\n",
        "            plt.close(fig)\n",
        "\n",
        "        print(f\"Successfully processed and saved leads for: {image_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_file}: {e}\")\n",
        "\n",
        "# Batch process all images in a folder\n",
        "def process_all_folders(folders, output_base_folder):\n",
        "    \"\"\"\n",
        "    Process all images in the given folders to extract ECG leads.\n",
        "\n",
        "    Parameters:\n",
        "    - folders: A list of folder paths containing ECG images.\n",
        "    - output_base_folder: The base directory where the processed images will be saved.\n",
        "    \"\"\"\n",
        "    valid_extensions = ('.jpg', '.jpeg', '.png')\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_base_folder, exist_ok=True)\n",
        "\n",
        "    for folder in folders:\n",
        "        if not os.path.exists(folder):\n",
        "            print(f\"Folder does not exist: {folder}\")\n",
        "            continue\n",
        "\n",
        "        # Process each image in the folder\n",
        "        image_files = [f for f in os.listdir(folder) if f.lower().endswith(valid_extensions)]\n",
        "        for image_file in image_files:\n",
        "            convert_image_lead(image_file, folder, output_base_folder)\n",
        "\n",
        "# Define paths to each folder containing the images\n",
        "MI = '/content/drive/MyDrive/MISSION CAPSTONE/ECG_DATASET/ECG Images of Myocardial Infarction Patients (240x12=2880)'\n",
        "Normal = '/content/drive/MyDrive/MISSION CAPSTONE/ECG_DATASET/Normal Person ECG Images (284x12=3408)'\n",
        "Abnormal = '/content/drive/MyDrive/MISSION CAPSTONE/ECG_DATASET/ECG Images of Patient that have abnormal heartbeat (233x12=2796)'\n",
        "H_MI = '/content/drive/MyDrive/MISSION CAPSTONE/ECG_DATASET/ECG Images of Patient that have History of MI (172x12=2064)'\n",
        "\n",
        "# List of folders to process\n",
        "folders = [MI, Normal, Abnormal, H_MI]\n",
        "\n",
        "# Define the base output folder where processed images will be saved\n",
        "output_base_folder = '/content/drive/MyDrive/MISSION CAPSTONE/Processed_ECG_Images'\n",
        "\n",
        "# Process all folders\n",
        "process_all_folders(folders, output_base_folder)\n"
      ],
      "metadata": {
        "id": "BBZj0t07ZBIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing lead images"
      ],
      "metadata": {
        "id": "HmXFBc09fVnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from skimage import measure, color\n",
        "from skimage.filters import gaussian\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread, imsave\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "# Function to extract and save signal leads from ECG images\n",
        "def extract_signal_leads(Leads, processed_base_folder):\n",
        "    \"\"\"\n",
        "    Extracts and saves signal leads from ECG images.\n",
        "\n",
        "    Parameters:\n",
        "        Leads (list): List of ECG lead images.\n",
        "        processed_base_folder (str): Base directory to save processed images.\n",
        "    \"\"\"\n",
        "    # Looping through the image list containing all leads from 1-13\n",
        "    for x, y in enumerate(Leads):\n",
        "        # Convert to grayscale, handling potential alpha channel\n",
        "        if y.shape[-1] == 4:  # Check if image has an alpha channel\n",
        "            y = y[:, :, :3]  # If so, select only the RGB channels\n",
        "        grayscale = color.rgb2gray(y)\n",
        "\n",
        "        # Smooth the image\n",
        "        blurred_image = gaussian(grayscale, sigma=0.7)\n",
        "\n",
        "        # Thresholding using Otsu's method\n",
        "        global_thresh = threshold_otsu(blurred_image)\n",
        "        binary_global = blurred_image < global_thresh\n",
        "\n",
        "        # Resize image for leads 1-11\n",
        "        if x != 12:\n",
        "            binary_global = resize(binary_global, (300, 450))\n",
        "\n",
        "        # Extract the parent folder and image filename from processed_base_folder\n",
        "        parent_folder, image_filename = os.path.split(processed_base_folder)\n",
        "        folder_name, _ = os.path.splitext(image_filename)  # Extract folder name\n",
        "\n",
        "        # Create the output directory if it doesn't exist\n",
        "        output_dir = os.path.join(parent_folder, folder_name)\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Save the preprocessed image\n",
        "        preprocessed_image_path = os.path.join(output_dir, f'Lead_{x + 1}_preprocessed_Signal.png')\n",
        "        imsave(preprocessed_image_path, binary_global)  # Using imsave instead of plt.savefig\n",
        "\n",
        "        # Find contours and get the signal contour\n",
        "        contours = measure.find_contours(binary_global, 0.8)\n",
        "        if contours:\n",
        "            contours_shape = sorted([contour.shape for contour in contours], reverse=True)[0:1]\n",
        "            for contour in contours:\n",
        "                if contour.shape in contours_shape:\n",
        "                    # Resize contour for saving\n",
        "                    contour_resized = resize(contour, (255, 2))\n",
        "                    # Save contour data (e.g., to a NumPy file)\n",
        "                    contour_data_path = os.path.join(output_dir, f'Lead_{x + 1}_Contour_Signal.npy')\n",
        "                    np.save(contour_data_path, contour_resized)\n",
        "\n",
        "    lead_no=x\n",
        "    #convert_csv(test,lead_no,processed_base_folder)\n",
        "    #scale_csv(test,lead_no,processed_base_folder)\n",
        "    # scale_csv_1D(test,lead_no,processed_base_folder)\n",
        "\n",
        "\n",
        "# Define the base directory where processed ECG images are stored\n",
        "processed_base_folder = '/content/drive/MyDrive/MISSION CAPSTONE/Processed_ECG_Images'\n",
        "\n",
        "# Loop through all subfolders in the base directory\n",
        "for subfolder in os.listdir(processed_base_folder):\n",
        "    subfolder_path = os.path.join(processed_base_folder, subfolder)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        # Create a list of leads by reading the images from the subfolder\n",
        "        Leads = [imread(os.path.join(subfolder_path, f'Lead_{i}_Signal.png')) for i in range(1, 14)]\n",
        "\n",
        "        # Call the extraction function for the current subfolder\n",
        "        extract_signal_leads(Leads, subfolder_path)\n",
        "\n",
        "        print(f\"Processed images in subfolder: {subfolder}\")\n",
        "\n",
        "print(\"Processing completed for all subfolders.\")"
      ],
      "metadata": {
        "id": "LAq3rjJOft9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert contour to a dataframe"
      ],
      "metadata": {
        "id": "p3aEnmpjUbIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil  # For moving files\n",
        "\n",
        "def convert_csv(contour_data, lead_number, processed_base_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Converts contour data to a Pandas DataFrame and saves it as a CSV file\n",
        "    in a subfolder within the output folder.\n",
        "\n",
        "    Parameters:\n",
        "        contour_data (np.ndarray): The contour data.\n",
        "        lead_number (int): The lead number (1-12 for ECG leads).\n",
        "        processed_base_folder (str): The original base folder where contour data\n",
        "                                       was located (used to extract target label and subfolder name).\n",
        "        output_folder (str): The base output folder where CSV files will be saved.\n",
        "    \"\"\"\n",
        "    # Extract target label from the original base folder name\n",
        "    target_label = os.path.basename(processed_base_folder)[:2]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(contour_data, columns=['X', 'Y'])\n",
        "    df['Target'] = target_label\n",
        "\n",
        "    # Construct CSV file path in the output folder, maintaining subfolder structure\n",
        "    subfolder_name = os.path.basename(processed_base_folder)  # Get subfolder name\n",
        "    output_subfolder = os.path.join(output_folder, subfolder_name)\n",
        "    os.makedirs(output_subfolder, exist_ok=True)  # Create subfolder if it doesn't exist\n",
        "    csv_file_path = os.path.join(output_subfolder, f\"{target_label}_{lead_number + 1}.csv\")\n",
        "\n",
        "    # Save DataFrame to CSV\n",
        "    df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "    print(f\"Saved contour data for lead {lead_number + 1} to: {csv_file_path}\")\n",
        "\n",
        "\n",
        "# Define the base directory where processed ECG images are stored\n",
        "processed_base_folder = '/content/drive/MyDrive/MISSION CAPSTONE/Processed_ECG_Images'\n",
        "\n",
        "# Create the final output folder \"processed_scaled_1\"\n",
        "final_output_folder = '/content/drive/MyDrive/MISSION CAPSTONE/processed_scaled_1'\n",
        "os.makedirs(final_output_folder, exist_ok=True)\n",
        "\n",
        "# Loop through all subfolders in the base directory\n",
        "for subfolder in os.listdir(processed_base_folder):\n",
        "    subfolder_path = os.path.join(processed_base_folder, subfolder)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        # Loop through all lead numbers (1-13)\n",
        "        for lead_number in range(13):\n",
        "            # Construct contour data file path\n",
        "            contour_data_path = os.path.join(subfolder_path, f'Lead_{lead_number + 1}_Contour_Signal.npy')\n",
        "\n",
        "            # Check if contour data file exists\n",
        "            if os.path.exists(contour_data_path):\n",
        "                # Load contour data\n",
        "                contour_data = np.load(contour_data_path)\n",
        "\n",
        "                # Call the convert_csv function, passing the output folder\n",
        "                convert_csv(contour_data, lead_number, subfolder_path, final_output_folder)\n",
        "\n",
        "        print(f\"Processed contours in subfolder: {subfolder}\")\n",
        "\n",
        "print(\"Processing completed. All CSV files saved to their respective subfolders in 'processed_scaled_1'.\")"
      ],
      "metadata": {
        "id": "rzbW7deFUjaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling to 1D"
      ],
      "metadata": {
        "id": "OSZtUCtdWYuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write code to scale the data for the processed_scaled_1 files we generated and save them in processed_scaled_1D add this # Scaling the data with MinMaxScaler\n",
        "#     scaler = MinMaxScaler()\n",
        "#     fit_transform_data = scaler.fit_transform(test)\n",
        "#     # Creating a DataFrame with the first column 'X' (scaled values)\n",
        "#     Normalized_Scaled = pd.DataFrame(fit_transform_data[:, 0], columns=['X'])\n",
        "#     # Plotting the scaled data\n",
        "#     fig6, ax6 = plt.subplots()\n",
        "#     plt.gca().invert_yaxis()  # Invert y-axis for ECG signal visualization\n",
        "#     ax6.plot(Normalized_Scaled, linewidth=1, color='black', linestyl\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the base directory where processed ECG images are stored\n",
        "processed_scaled_1_folder = '/content/drive/MyDrive/MISSION CAPSTONE/processed_scaled_1'\n",
        "processed_scaled_1D_folder = '/content/drive/MyDrive/MISSION CAPSTONE/processed_scaled_1D'\n",
        "os.makedirs(processed_scaled_1D_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "# Loop through all subfolders in the base directory\n",
        "for subfolder in os.listdir(processed_scaled_1_folder):\n",
        "    subfolder_path = os.path.join(processed_scaled_1_folder, subfolder)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        for filename in os.listdir(subfolder_path):\n",
        "            if filename.endswith(\".csv\"):\n",
        "                file_path = os.path.join(subfolder_path, filename)\n",
        "                df = pd.read_csv(file_path)\n",
        "\n",
        "                # Scaling the data with MinMaxScaler\n",
        "                test = df[['X', 'Y']]\n",
        "                scaler = MinMaxScaler()\n",
        "                fit_transform_data = scaler.fit_transform(test)\n",
        "\n",
        "                # Creating a DataFrame with the first column 'X' (scaled values)\n",
        "                Normalized_Scaled = pd.DataFrame(fit_transform_data[:, 0], columns=['X'])\n",
        "\n",
        "                # Create a new subfolder in processed_scaled_1D with the same name as the existing subfolder\n",
        "                new_subfolder_path = os.path.join(processed_scaled_1D_folder, subfolder)\n",
        "                os.makedirs(new_subfolder_path, exist_ok=True)\n",
        "\n",
        "               # Append '_scaled_1D' to the original filename (before the .csv)\n",
        "                output_filename = filename.replace('.csv', '_scaled_1D.csv')\n",
        "                output_file_path = os.path.join(new_subfolder_path, output_filename)\n",
        "\n",
        "                # Save the scaled data\n",
        "                Normalized_Scaled.to_csv(output_file_path, index=False)\n",
        "\n",
        "                # Plotting the scaled data (optional)\n",
        "                #fig6, ax6 = plt.subplots()\n",
        "                #plt.gca().invert_yaxis()  # Invert y-axis for ECG signal visualization\n",
        "                #ax6.plot(Normalized_Scaled, linewidth=1, color='black', linestyle='-')\n",
        "                #plt.title('Scaled ECG Signal')\n",
        "                #plt.show()\n",
        "\n",
        "print(\"Scaling and saving completed.\")"
      ],
      "metadata": {
        "id": "lGDHUDNCUokm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # prompt: organize the generated folders in processed_scaled_1D into  main folders MI, HB, PMI, and Normal by using their first two letters\n",
        "\n",
        "# Define the source and destination folders\n",
        "source_folder = '/content/drive/MyDrive/MISSION CAPSTONE/processed_scaled_1D'\n",
        "destination_folder = '/content/drive/MyDrive/MISSION CAPSTONE/organized_processed_scaled_1D'\n",
        "\n",
        "# Create the main destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Create the subfolders MI, HB, PMI, and Normal\n",
        "main_folders = ['MI', 'HB', 'PMI', 'Normal']\n",
        "for folder in main_folders:\n",
        "  os.makedirs(os.path.join(destination_folder, folder), exist_ok=True)\n",
        "\n",
        "# Iterate through the subfolders in the source folder\n",
        "for subfolder in os.listdir(source_folder):\n",
        "  subfolder_path = os.path.join(source_folder, subfolder)\n",
        "\n",
        "  # Check if it's a directory\n",
        "  if os.path.isdir(subfolder_path):\n",
        "    # Extract the first two letters from the subfolder name\n",
        "    first_two_letters = subfolder[:2]\n",
        "\n",
        "    # Determine the main folder based on the first two letters\n",
        "    if first_two_letters == 'MI':\n",
        "      target_folder = 'MI'\n",
        "    elif first_two_letters == 'HB':\n",
        "      target_folder = 'HB'\n",
        "    elif first_two_letters == 'PM':\n",
        "      target_folder = 'PMI'\n",
        "    else:\n",
        "      target_folder = 'Normal'\n",
        "\n",
        "    # Construct the destination path for the subfolder\n",
        "    destination_subfolder_path = os.path.join(destination_folder, target_folder, subfolder)\n",
        "\n",
        "    # Move the subfolder to the appropriate main folder\n",
        "    shutil.move(subfolder_path, destination_subfolder_path)\n",
        "\n",
        "print(\"Folders organized successfully!\")"
      ],
      "metadata": {
        "id": "Wbs7_QtO_N_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling to 2D"
      ],
      "metadata": {
        "id": "BWnYUC3fUrj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def scale_csv(csv_file_path, lead_number, output_folder):\n",
        "    \"\"\"\n",
        "    Scales the X and Y coordinates in a CSV file using MinMaxScaler and saves the scaled data to a new CSV file.\n",
        "\n",
        "    Parameters:\n",
        "        csv_file_path (str): Path to the CSV file containing X and Y coordinates.\n",
        "        lead_number (int): The lead number (1-12 for ECG leads).\n",
        "        output_folder (str): The base output folder where scaled CSV files will be saved.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "    file_name = os.path.basename(csv_file_path)\n",
        "    target_label = file_name[:2]  # Extract the first two characters of the file name for the target label\n",
        "\n",
        "    # Extract and scale X and Y columns\n",
        "    XY_data = df[['X', 'Y']].values\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(XY_data)\n",
        "    scaled_df = pd.DataFrame(scaled_data, columns=['X', 'Y'])\n",
        "\n",
        "    # Add the target label column\n",
        "    scaled_df['Target'] = target_label\n",
        "\n",
        "    # Save the scaled data to a new CSV file, appending \"_scaled_2D\" to the file name\n",
        "    output_file_path = os.path.join(output_folder, f\"{target_label}_{lead_number + 1}_scaled_2D.csv\")\n",
        "    scaled_df.to_csv(output_file_path, index=False)\n",
        "    print(f\"Scaled 2D data saved to: {output_file_path}\")\n",
        "\n",
        "\n",
        "# Define the base directory where processed ECG images are stored\n",
        "processed_scaled_1_folder = '/content/drive/MyDrive/MISSION CAPSTONE/processed_scaled_1'\n",
        "processed_scaled_2D_folder = '/content/drive/MyDrive/MISSION CAPSTONE/processed_scaled_2D'\n",
        "os.makedirs(processed_scaled_2D_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
        "\n",
        "# Loop through all subfolders in the base directory\n",
        "for subfolder in os.listdir(processed_scaled_1_folder):\n",
        "    subfolder_path = os.path.join(processed_scaled_1_folder, subfolder)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        for filename in os.listdir(subfolder_path):\n",
        "            if filename.endswith(\".csv\"):\n",
        "                file_path = os.path.join(subfolder_path, filename)\n",
        "                lead_number_str = filename.split('_')[1].split('.')[0]  # Extract lead number from file name\n",
        "\n",
        "                # Ensure the lead number is valid\n",
        "                if lead_number_str.isdigit():\n",
        "                    lead_number = int(lead_number_str) - 1\n",
        "\n",
        "                    # Create a new subfolder in the output folder (2D scaled data) with the same name as the original\n",
        "                    new_subfolder_path = os.path.join(processed_scaled_2D_folder, subfolder)\n",
        "                    os.makedirs(new_subfolder_path, exist_ok=True)\n",
        "\n",
        "                    # Perform scaling and save the results\n",
        "                    scale_csv(file_path, lead_number, new_subfolder_path)\n",
        "\n",
        "print(\"Scaling and saving completed.\")\n"
      ],
      "metadata": {
        "id": "yv4S0AvZ91Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: sort the csv fikes in the above code\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def sort_csv_files(source_folder, destination_folder):\n",
        "  \"\"\"\n",
        "  Sorts CSV files in subfolders based on their label (first two characters of filename).\n",
        "\n",
        "  Args:\n",
        "    source_folder: The folder containing subfolders with CSV files.\n",
        "    destination_folder: The folder where sorted CSV files will be placed.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create the main destination folder if it doesn't exist\n",
        "  os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "  # Create the subfolders MI, HB, PMI, and Normal\n",
        "  main_folders = ['MI', 'HB', 'PMI', 'Normal']\n",
        "  for folder in main_folders:\n",
        "    os.makedirs(os.path.join(destination_folder, folder), exist_ok=True)\n",
        "\n",
        "  # Iterate through the subfolders in the source folder\n",
        "  for subfolder in os.listdir(source_folder):\n",
        "    subfolder_path = os.path.join(source_folder, subfolder)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(subfolder_path):\n",
        "      for filename in os.listdir(subfolder_path):\n",
        "        if filename.endswith(\".csv\"):\n",
        "          # Extract the first two letters from the filename\n",
        "          first_two_letters = filename[:2]\n",
        "\n",
        "          # Determine the main folder based on the first two letters\n",
        "          if first_two_letters == 'MI':\n",
        "            target_folder = 'MI'\n",
        "          elif first_two_letters == 'HB':\n",
        "            target_folder = 'HB'\n",
        "          elif first_two_letters == 'PM':\n",
        "            target_folder = 'PMI'\n",
        "          else:\n",
        "            target_folder = 'Normal'\n",
        "\n",
        "          # Construct the destination path for the CSV file\n",
        "          destination_file_path = os.path.join(destination_folder, target_folder, filename)\n",
        "\n",
        "          # Move the CSV file to the appropriate main folder\n",
        "          shutil.move(os.path.join(subfolder_path, filename), destination_file_path)\n",
        "\n",
        "  print(\"CSV files organized successfully!\")\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "source_folder = '/content/drive/MyDrive/MISSION CAPSTONE/processed_scaled_1D'\n",
        "destination_folder = '/content/drive/MyDrive/MISSION CAPSTONE/organized_processed_scaled_1D'\n",
        "sort_csv_files(source_folder, destination_folder)"
      ],
      "metadata": {
        "id": "6377XB_6UwdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def organize_folders(source_folder, destination_folder):\n",
        "    \"\"\"\n",
        "    Organizes subfolders in the source folder into main folders (MI, HB, PMI, Normal)\n",
        "    based on the first two letters of the subfolder name.\n",
        "\n",
        "    Args:\n",
        "        source_folder: The path to the folder containing subfolders to organize.\n",
        "        destination_folder: The path to the folder where organized subfolders will be moved.\n",
        "    \"\"\"\n",
        "    for subfolder in os.listdir(source_folder):\n",
        "        subfolder_path = os.path.join(source_folder, subfolder)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            main_folder_name = subfolder[:2]  # Extract the first two letters\n",
        "            main_folder_path = os.path.join(destination_folder, main_folder_name)\n",
        "            os.makedirs(main_folder_path, exist_ok=True)\n",
        "            new_subfolder_path = os.path.join(main_folder_path, subfolder)\n",
        "            shutil.move(subfolder_path, new_subfolder_path)\n",
        "\n",
        "# Define source and destination folders\n",
        "source_folder = '/content/drive/MyDrive/MISSION CAPSTONE/processed_scaled_2D'\n",
        "destination_folder = '/content/drive/MyDrive/MISSION CAPSTONE/organized_processed_scaled_2D'\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Organize the folders\n",
        "organize_folders(source_folder, destination_folder)\n",
        "\n",
        "print(\"Folders organized successfully!\")"
      ],
      "metadata": {
        "id": "oYzQLVP5Avf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort 1D scaled files"
      ],
      "metadata": {
        "id": "nCMoKeO_k2HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def sort_and_save_files_by_number(base_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Sorts CSV files in all subfolders of the given base folder based on the number found after the first underscore,\n",
        "    and saves them to a new destination folder.\n",
        "\n",
        "    Parameters:\n",
        "        base_folder (str): Path to the base folder containing subfolders (MI, HB, PMI, Normal).\n",
        "        output_folder (str): Path to the output folder where sorted files will be saved.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)  # Ensure the output folder exists\n",
        "\n",
        "    # Loop through all primary folders (MI, HB, PMI, Normal)\n",
        "    for main_folder in os.listdir(base_folder):\n",
        "        main_folder_path = os.path.join(base_folder, main_folder)\n",
        "\n",
        "        if os.path.isdir(main_folder_path):\n",
        "            # Create corresponding folder in the output folder\n",
        "            output_main_folder = os.path.join(output_folder, main_folder)\n",
        "            os.makedirs(output_main_folder, exist_ok=True)\n",
        "\n",
        "            # Loop through each subfolder (MI(1), MI(2), etc.)\n",
        "            for subfolder in os.listdir(main_folder_path):\n",
        "                subfolder_path = os.path.join(main_folder_path, subfolder)\n",
        "\n",
        "                if os.path.isdir(subfolder_path):\n",
        "                    # Create corresponding subfolder in the output folder\n",
        "                    output_subfolder = os.path.join(output_main_folder, subfolder)\n",
        "                    os.makedirs(output_subfolder, exist_ok=True)\n",
        "\n",
        "                    # Gather CSV files and sort them by the number after the first underscore\n",
        "                    csv_files = [f for f in os.listdir(subfolder_path) if f.endswith('.csv')]\n",
        "\n",
        "                    # Debug: Print the found CSV files\n",
        "                    print(f\"Found files in {subfolder_path}: {csv_files}\")\n",
        "\n",
        "                    # Sort files by the numeric part of the name, using a custom key to extract numbers\n",
        "                    def sort_key(filename):\n",
        "                        parts = filename.split('_')\n",
        "                        if len(parts) > 1:\n",
        "                            try:\n",
        "                                return int(parts[1].split('.')[0])\n",
        "                            except ValueError:\n",
        "                                return float('inf')  # Put non-numeric values at the end\n",
        "                        return float('inf')  # Put files without underscores at the end\n",
        "\n",
        "                    sorted_csv_files = sorted(csv_files, key=sort_key)\n",
        "\n",
        "                    # Debug: Print the sorted file names\n",
        "                    print(f\"Sorted files for {subfolder}: {sorted_csv_files}\")\n",
        "\n",
        "                    # Copy sorted files to the new location\n",
        "                    for file in sorted_csv_files:\n",
        "                        src_file_path = os.path.join(subfolder_path, file)\n",
        "                        dest_file_path = os.path.join(output_subfolder, file)\n",
        "                        shutil.copy(src_file_path, dest_file_path)\n",
        "\n",
        "                    print(f\"Copied sorted files from {subfolder_path} to {output_subfolder}\")\n",
        "\n",
        "# --- Main Execution ---\n",
        "organized_processed_scaled_1D_folder = '/content/drive/MyDrive/MISSION CAPSTONE/organized_processed_scaled_1D'\n",
        "final_sorted_output_folder = '/content/drive/MyDrive/MISSION CAPSTONE/final_sort_scaled_1D'\n",
        "\n",
        "# Call the function to sort and save files by the number after the first underscore\n",
        "sort_and_save_files_by_number(organized_processed_scaled_1D_folder, final_sorted_output_folder)\n",
        "\n",
        "print(\"Sorting and saving of files based on the numbers completed.\")"
      ],
      "metadata": {
        "id": "yidnXMxab8-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine leads of each image 1-12"
      ],
      "metadata": {
        "id": "cEjpKGMQL1Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print out the files in HB(1) in final_sorted_scaled_2D folder path /content/drive/MyDrive/MISSION CAPSTONE/final_sort_scaled_1D/HB/HB(1)\n",
        "\n",
        "import os\n",
        "\n",
        "# Define the folder path you want to list files from\n",
        "folder_path = '/content/drive/MyDrive/MISSION CAPSTONE/final_sort_scaled_1D/HB/HB(1)'\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(folder_path):\n",
        "    # List all files in the folder\n",
        "    files_in_folder = os.listdir(folder_path)\n",
        "\n",
        "    # Print the list of files\n",
        "    for file_name in files_in_folder:\n",
        "        print(file_name)\n",
        "else:\n",
        "    print(f\"The folder '{folder_path}' does not exist.\")"
      ],
      "metadata": {
        "id": "a8PPLj65zfSA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "mount_file_id": "1PGqga2BpTirih9S-qZ36iUiHotrZvVdn",
      "authorship_tag": "ABX9TyNfA7GJfH5/qjfUjVBa16zl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}